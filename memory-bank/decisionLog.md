## ドキュメント統合計画

1.  **現在のドキュメント構造の把握**:
    *   `docs/README.md` ファイルを再度確認し、ドキュメントの全体構造を把握します。
    *   `docs` ディレクトリのファイルリストを確認し、新規または変更されたファイルがないか確認します。
    *   `docs/EXPLANATION/integrated_architecture.md` ファイル (もし存在すれば) を確認します。これはリファクタリング後の統合されたアーキテクチャのドキュメントである可能性があります。

2.  **リファクタリングの詳細の確認**:
    *   ユーザーにリファクタリングの主な内容と、ドキュメントのどの部分が特に影響を受けたか質問します。
    *   リファクタリングによってドキュメントにどのような変更が加えられたかを明確にします。

3.  **ドキュメント更新計画の作成**:
    *   リファクタリングによる変更に基づいて、ドキュメントのどの部分を更新する必要があるかを特定します。
    *   更新の優先順位を決定します (例: 新機能、重要な変更点など)。
    *   ドキュメント更新のスケジュールを作成します (必要に応じて)。

4.  **ドキュメント更新の実施**:
    *   `read_file` ツールを使用して、更新対象のドキュメントファイルの内容を読み込みます。
    *   `apply_diff` ツールを使用して、ドキュメントに必要な変更を適用します。
    *   新しいドキュメントを追加する必要がある場合は、`write_to_file` ツールを使用します。

5.  **ドキュメント更新の確認**:
    *   更新されたドキュメントが正しく記述されているか、誤りや矛盾がないか確認します。
    *   可能であれば、ドキュメントをローカルでビルドし、ウェブサイトに公開する前にプレビューします。

6.  **ドキュメント更新の完了**:
    *   更新されたドキュメントをウェブサイトまたは適切な場所に公開します。
    *   ユーザーにドキュメント更新の完了を報告します。

**Mermaid図**

```mermaid
graph LR
    A[現在のドキュメント構造の把握] --> B{リファクタリングの詳細の確認};
    B --> C[ドキュメント更新計画の作成];
    C --> D[ドキュメント更新の実施];
    D --> E[ドキュメント更新の確認];
    E --> F[ドキュメント更新の完了];

## ドキュメント削減の決定と計画 (2025-04-18)

**背景:**
ユーザーより、ドキュメントのファイル数が多すぎる（11ファイル）ため、量を約三分の一程度に削減したいとのフィードバックを受けました。

**決定:**
ドキュメントのファイル数を削減し、内容を整理統合します。目標ファイル数は約7ファイルとします。

**計画:**
1.  **必須ドキュメントの維持:** 以下のファイルはライブラリの利用・開発に必須であるため維持します。
    *   `docs/README.md` (ドキュメント概要)
    *   `docs/getting_started.md` (入門ガイド)
    *   `docs/developer_guide.md` (開発者ガイド)
    *   `docs/REFERENCE/api.md` (APIリファレンス)
    *   `docs/REFERENCE/configuration.md` (設定ファイル仕様)
    *   `docs/REFERENCE/models.md` (サポートモデル詳細)
2.  **解説・設計関連ドキュメントの統合:** 「解説」セクションのファイル (`design_decisions.md`, `legacy_info.md`, `refactoring.md`) および `web_api_annotator_design.md` の内容を、`docs/EXPLANATION/integrated_architecture.md` に統合します。
    *   `docs/EXPLANATION/integrated_architecture.md` を中心に、設計決定の背景、ModelLoad クラスの詳細、Web API アノテーター設計、旧ライブラリ情報の要約を含めるように内容を再構成します。
3.  **不要ファイルの削除:** 統合元となった以下のファイルを削除します。
    *   `docs/EXPLANATION/design_decisions.md`
    *   `docs/EXPLANATION/legacy_info.md`
    *   `docs/EXPLANATION/refactoring.md`
    *   `docs/web_api_annotator_design.md`
4.  **README.md の更新:** 削除・統合されたファイルへのリンクを修正します。
5.  **統合ドキュメントの確認:** 統合後の `integrated_architecture.md` の内容を確認し、情報が網羅されており、かつ簡潔にまとめられていることを確認します。

#### [バグ修正] ログ出力が多重になる問題の修正

- **発生日:** 2025-04-19
- **影響範囲:** 全ログ出力（ファイル・コンソール）
- **現象:** ログが同じ内容で2回以上出力される
- **原因:** `core/utils.py` の logger 初期化処理が、複数回importされることで何度も実行され、logger.addが多重に呼ばれていた
- **修正方針:**
  1. logger初期化処理を `init_logger` 関数として分離し、多重初期化を防ぐガードを追加
  2. loggerの初期化は `__init__.py` でプロセス起動時に1回だけ明示的に呼ぶ
  3. loggerのimport経路を統一し、絶対/相対importの混在を避ける
- **修正理由:** ログの可読性・運用性向上、不要なI/O負荷の削減
- **影響:** 既存のlogger利用コードには影響なし。ログ出力が正常化される

#### [設計変更] レジストリ・logger初期化の即時実行廃止と明示的初期化への移行

- **発生日:** 2025-04-19
- **内容:**
  - `core/registry.py` の末尾で行っていた logger によるログ出力および `register_annotators()` の即時実行（import時自動実行）を廃止。
  - 代わりに、logger初期化（`init_logger()`）→レジストリ初期化（`register_annotators()`）を明示的な初期化関数でのみ実行する設計に変更。
- **理由:**
  - loggerのsink設定前にログ出力が発生し、ログが出力されない問題を根本解決するため。
  - import時の副作用（グローバル状態変更や重い処理）を排除し、テスト・再利用性・保守性を向上させるため。
  - Pythonのベストプラクティス（import時は副作用を持たせない）に従うため。
- **影響:**
  - logger/レジストリ初期化はエントリーポイントやAPI利用時に明示的に呼ぶ必要がある。
  - 既存のimport時自動初期化に依存したコードは修正が必要。
  - ログ出力の信頼性・初期化順序の一貫性が向上。

#### [機能追加/バグ修正] CUDA非対応環境でのCPUフォールバック実装

- **発生日:** 2025-04-19
- **背景:** ユーザー環境によっては NVIDIA ドライバや CUDA Toolkit がインストールされていない、あるいは PyTorch が CUDA 非対応ビルドである場合がある。このような環境で設定ファイル (`annotator_config.toml`) にて `device = "cuda"` が指定されているモデルを使用しようとすると、モデルロード時や推論時に CUDA 関連のエラーが発生し、処理が中断してしまう。
- **内容:**
    1.  **有効なデバイス判定ロジックの追加:** `core/utils.py` に `determine_effective_device` 関数を追加。この関数は、設定ファイルで要求されたデバイス (`requested_device`) と、`torch.cuda.is_available()` や ONNX Runtime のプロバイダー情報などを基に、実際にその環境で利用可能なデバイス (`"cuda"` または `"cpu"`) を判定する。
    2.  **デバイス決定処理の適用:**
        *   `core/base.py` の `BaseAnnotator.__init__` 内で、設定から読み込んだ `requested_device` を `determine_effective_device` に渡し、実際に使用する `self.device` を決定するように修正。
        *   `core/model_factory.py` の各ローダークラス (`TransformersLoader`, `ONNXLoader` など) や `ModelLoad` の関連メソッド内で、モデルのロードやデバイスへの転送を行う際に、この決定された有効なデバイスを使用するように修正（または、`BaseAnnotator` から渡された `self.device` を利用する）。
    3.  **警告ログの追加:** CUDA が要求されたが利用できず CPU にフォールバックする場合、ユーザーにその旨を知らせる警告ログ (`core/utils.py` 内) を出力するようにした。
- **理由:** CUDA 環境がない、または不完全なユーザーでも、CPU を利用してライブラリの機能（CUDA必須モデルを除く）を実行できるようにするため。エラーによる予期せぬ処理中断を防ぎ、ユーザーエクスペリエンスを向上させる。
- **影響:**
    - CUDA が利用できない環境でも、CPU で動作可能なモデルであれば自動的に CPU にフォールバックして動作するようになる。
    - ユーザーは環境差異を意識することなく、設定ファイルで `"cuda"` を指定したままにしておける（ただし、CPUでの実行は遅くなる可能性がある）。
    - フォールバック発生時に警告ログが出力されるため、意図せずCPUで実行されている状況や、パフォーマンス低下の可能性を認識できる。

#### [設計変更] 全モデルローダーへの早期サイズ計算とメモリ管理強化の実装

- **発生日:** 2025-04-20 (推定)
- **対象:** `core/model_factory.py` 内の全ローダークラス (`TransformersLoader`, `TransformersPipelineLoader`, `ONNXLoader`, `TensorFlowLoader`, `CLIPLoader`)
- **内容:**
    1.  **早期サイズ計算:** 各ローダーに `_get_or_calculate_model_size` メソッドを追加。モデルロード前に以下の順でサイズ (MB) を取得・計算する。
        *   静的キャッシュ (`ModelLoad._MODEL_SIZES`)
        *   設定ファイル (`annotator_config.toml` の `estimated_size_gb`)
        *   （上記にない場合）モデルに応じた方法で一時的にロード/解析して計算 (CPU上で実行し、リソースは解放)。
    2.  **サイズ自動保存:** 計算されたサイズは静的キャッシュに保存し、同時に `annotator_config.toml` (システム設定) に `estimated_size_gb` として保存する。次回以降は計算不要となる。
    3.  **事前メモリチェック:** 取得/計算したサイズに基づき、`_check_memory_before_load` でロードに必要なシステムメモリが利用可能か確認する。不足時はロードを中止。
    4.  **キャッシュクリア改善:** 取得/計算したサイズに基づき、`_clear_cache_if_needed` でキャッシュ削除要否を判断する。
    5.  **ロードフロー統一:** 上記ステップを組み込み、全ローダーの `load_components` メソッドのフローを統一。
- **理由:**
    - モデルロード時のメモリ不足によるクラッシュを事前に防ぐため。
    - 不明なモデルサイズを初回ロード時に計算・保存することで、2回目以降のロードを高速化するため。
    - 各ローダーのメモリ管理ロジックを統一し、保守性を向上させるため。
- **影響:**
    - 初回ロード時にサイズ計算のため若干時間がかかる場合があるが、2回目以降は高速化される。
    - メモリ不足による予期せぬエラーが削減される。
    - `annotator_config.toml` に `estimated_size_gb` が自動的に追記・更新される。

#### [設計変更] ModelConfigRegistry のシステム/ユーザー設定分離と永続化機能追加

- **発生日:** 2025-04-20 (推定、早期サイズ計算と同時期)
- **対象:** `core/config.py` の `ModelConfigRegistry` クラス
- **内容:**
    1.  **設定データの分離:** 内部データをシステム設定 (`_system_config_data`) とユーザー設定 (`_user_config_data`) に分離。
    2.  **マージロジック:** ユーザー設定がシステム設定を上書きする形でマージされた設定ビュー (`_merged_config_data`) を作成・利用する `_merge_configs` メソッドを追加。`get` メソッドはこのマージビューから値を取得する。
    3.  **システム設定更新メソッド:**
        *   `set_system_value`: メモリ上のシステム設定を更新するメソッドを追加 (例: 計算済みモデルサイズの保存用)。
        *   `save_system_config`: メモリ上のシステム設定を指定ファイルに永続化するメソッドを追加。
    4.  **ユーザー設定更新/保存メソッド:**
        *   `set` メソッドはメモリ上の *ユーザー* 設定を更新するように変更。
        *   `save_user_config`: メモリ上のユーザー設定を指定ファイルに永続化するメソッドを維持/追加。
    5.  **ロード処理:** `load` メソッドはシステム設定とユーザー設定の両方を読み込み、マージ処理を実行するように変更。
- **理由:**
    - システムデフォルト設定の保護: ユーザー設定や自動更新（モデルサイズ保存など）がシステム提供のデフォルト設定を上書きしないようにするため。
    - 設定上書きの明確化: 基本設定とユーザーによる変更を明確に分離するため。
    - 計算済みサイズの永続化: モデルローダーが計算した `estimated_size_gb` をユーザー設定ファイルではなく、*システム* 設定ファイルに保存できるようにするため。これにより、ライブラリ利用者は影響を受けずに次回以降のロードが高速化される。
    - ユーザー設定の永続化: ユーザーが明示的にカスタム設定を保存する手段を提供するため。
    - 設定管理の一元化: 設定の読み込み、アクセス、保存に関するロジックを `ModelConfigRegistry` 内に集約するため。
- **影響:**
    - 設定値の取得 (`get`) は、システムとユーザー設定がマージされた結果を返す。
    - `set` メソッドはユーザー設定のみを更新する。
    - モデルローダーによるサイズ自動保存はシステム設定ファイル (`resources/system/annotator_config.toml`) に反映される。
    - ユーザーは `save_user_config` で自身のカスタム設定を保存できる。

#### [リファクタリング] `model_factory._CLIPLoader._create_clip_model_internal` の複雑度削減 (Ruff C901 対応)

- **発生日:** 2025-04-20 (推定)
- **対象:** `src/image_annotator_lib/core/model_factory.py` 内の `_CLIPLoader._create_clip_model_internal` メソッド
- **背景:** `_create_clip_model_internal` メソッドが、CLIP プロセッサ/モデルのロード、分類器ヘッドの重みロード、構造推測、活性化関数設定、分類器インスタンス生成・ロードなど、多数の責務を担っており、複雑度が高く (Ruff C901 違反)、保守性に課題があった。
- **内容:**
    1.  **構造推測の分離:** 分類器ヘッドの隠れ層サイズを `state_dict` から推測するロジックを、独立したヘルパーメソッド `_infer_classifier_structure` に抽出。
    2.  **ベースコンポーネントロードの分離:** CLIP プロセッサとベース CLIP モデルのロード処理を、独立したヘルパーメソッド `_load_base_clip_components` に抽出。
    3.  **分類器ヘッド作成/ロードの分離:** `Classifier` インスタンスの生成、活性化関数の設定、`state_dict` からの重みロード処理を、独立したヘルパーメソッド `_create_and_load_classifier_head` に抽出。
    4.  **本体メソッドの単純化:** 元の `_create_clip_model_internal` は、上記ヘルパーメソッドを順番に呼び出す形にリファクタリング。
- **理由:**
    - メソッドの複雑度を低減し、Ruff C901 違反を解消するため。
    - 各処理ステップの責務を明確にし、可読性と保守性を向上させるため。
    - 単体テストを容易にするため（ヘルパーメソッド単位でのテストが可能に）。
- **影響:**
    - `_create_clip_model_internal` のコードが大幅に簡潔化された。
    - CLIP モデルロード処理全体の機能的な変更はない。
    - 将来的な設定ファイルによる構造定義への移行など、さらなる改善が容易になった。

#### [リファクタリング] `ModelLoad` 状態変数アクセスのカプセル化

- **発生日:** 2025-04-21 (推定)
- **対象:** `src/image_annotator_lib/core/model_factory.py` の `ModelLoad` クラス
- **内容:**
    1.  `_MEMORY_USAGE`, `_MODEL_LAST_USED` といったクラス変数へのアクセスをカプセル化するため、以下の内部ヘルパーメソッド (`@classmethod`) を追加:
        *   `_get_current_cache_usage()`: 現在のキャッシュ使用量を返す。
        *   `_get_models_sorted_by_last_used()`: 最終使用時刻でソートされたモデルリストを返す。
        *   `_get_model_memory_usage(model_name)`: 特定モデルのメモリ使用量を返す。
    2.  `_clear_cache_internal` および `cache_to_main_memory` メソッド内で、クラス変数への直接アクセスを、上記ヘルパーメソッドの呼び出しに置き換えた。
- **理由:**
    - **カプセル化の向上:** クラスの状態変数の内部実装を隠蔽し、外部からの直接的な依存を減らすため。
    - **保守性の向上:** 状態変数へのアクセスロジックを一箇所に集約することで、将来的な仕様変更（例: 状態管理方法の変更）を容易にするため。
    - **可読性の向上:** メソッド名によって「何を取得しようとしているか」の意図を明確にし、コードの理解を助けるため (例: `sum(cls._MEMORY_USAGE.values())` より `cls._get_current_cache_usage()` の方が意図が明確)。
- **影響:**
    - `ModelLoad` クラスの内部的な実装変更であり、外部インターフェースや機能的な動作に変更はない。
    - コードの内部品質が向上した。
